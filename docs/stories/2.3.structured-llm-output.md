# Story 2.3: Structured LLM Output Integration & Schema-Constrained Processing

## Status
**Completed** - MEDICAL SAFETY LLM ESCALATION WITH CORRECTED PARSING METHODOLOGY

## Story (MEDICAL SAFETY LLM ESCALATION - COURSE CORRECTED)
**As a** clinical NLP system processing critical medical orders,  
**I want** to implement medical safety-driven LLM escalation (Tier 3.5) that triggers when confidence falls below 85% threshold to ensure clinical accuracy,  
**so that** I maintain medical safety standards while optimizing costs through intelligent 4-tier processing with corrected LLM parsing methodology that properly extracts embedded medical data.

## MEDICAL SAFETY LLM ESCALATION - ACTUAL IMPLEMENTATION WITH COURSE CORRECTION

## Acceptance Criteria (MEDICAL SAFETY IMPLEMENTATION)

1. [x] **Medical Safety Escalation**: 85% confidence threshold triggers LLM escalation for critical medical accuracy
2. [x] **4-Tier Architecture**: Tier 3.5 LLM escalation added after regex processing for medical safety 
3. [x] **Corrected LLM Parsing**: Fixed methodology that properly extracts embedded dosage/frequency data from medication objects
4. [x] **Pydantic Schema Validation**: Complete clinical data models with validation (MedicationOrder, LabTest, DiagnosticProcedure)
5. [x] **Weighted Confidence Scoring**: Medications/conditions (3x), dosages/frequencies (2x), other entities (1x) for medical priority
6. [x] **Cost Controls**: Configurable request limits, timeout handling, and automatic fallback to prevent runaway costs
7. [x] **Instructor Integration**: Uses OpenAI GPT-4o-mini + Instructor for structured output with proper parsing methodology

## Medical Safety Escalation System (COURSE-CORRECTED)

**CRITICAL UPDATE:** Previous 5-rule escalation system replaced with medical safety confidence-based escalation due to corrected analysis showing LLM superiority (89.2% vs 49.4% F1 score).

**Medical Safety Escalation Criteria:**
- **85% Confidence Threshold** - Escalate when weighted confidence below medical safety threshold
- **Weighted Scoring** - Critical medical entities (medications/conditions) weighted 3x for safety
- **Entity Count Validation** - Minimum 3 entities expected for clinical text with medical indicators
- **Clinical Text Detection** - Escalate when clinical keywords present but insufficient entities
- **Cost Protection** - Configurable limits prevent runaway API costs while ensuring medical accuracy

**Configuration Environment Variables:**
- `LLM_ESCALATION_ENABLED=true` (enables Tier 3.5)
- `LLM_ESCALATION_THRESHOLD=0.85` (85% medical safety threshold)  
- `LLM_ESCALATION_CONFIDENCE_CHECK=weighted_average` (medical priority weighting)
- `LLM_ESCALATION_MIN_ENTITIES=3` (minimum for clinical text)
- `LLM_ESCALATION_MAX_REQUESTS_PER_HOUR=100` (cost control)

## Tasks / Subtasks

- [ ] **Task 1: Setup LLM integration environment** (AC: 1)
  - [ ] Install and configure PydanticAI or Instructor + OpenAI libraries
  - [ ] Setup OpenAI API integration with structured output capabilities
  - [ ] Create LLM client with proper authentication and error handling
  - [ ] Configure LLM model selection (GPT-4o mini recommended for cost/performance)
  - [ ] Implement request rate limiting and usage monitoring

- [ ] **Task 2: Design medical data schemas** (AC: 2, 3)
  - [ ] Create Pydantic schemas for medication orders (drug, dosage, frequency, duration)
  - [ ] Design schemas for laboratory orders (test type, timing, specimen requirements)
  - [ ] Create procedure order schemas (procedure type, scheduling, preparation)
  - [ ] Implement clinical context schemas (symptoms, indications, patient history)
  - [ ] Add cross-field validation rules and medical constraints

- [ ] **Task 3: Implement schema-constrained slot filling** (AC: 3)
  - [ ] Create LLM prompt templates for medical information extraction
  - [ ] Implement structured output generation with schema enforcement
  - [ ] Add medical reasoning capabilities for complex clinical scenarios
  - [ ] Create slot filling logic for incomplete or ambiguous medical orders
  - [ ] Implement confidence scoring for LLM-generated structured data

- [ ] **Task 4: Integrate with existing NLP pipeline** (AC: 4)
  - [ ] Modify NLP pipeline to include structured LLM processing after RAG enhancement
  - [ ] Combine spaCy entity extraction, RAG terminology, and LLM structured output
  - [ ] Create data fusion logic to merge multiple NLP processing results
  - [ ] Preserve entity extraction and RAG results while adding LLM insights
  - [ ] Update response models to include structured LLM output

- [ ] **Task 5: Implement medical validation and reasoning** (AC: 5)
  - [ ] Create medical dosage calculation validation
  - [ ] Implement frequency and timing validation logic
  - [ ] Add basic contraindication checking against common drug interactions
  - [ ] Create medical reasonableness checks (dose ranges, frequency limits)
  - [ ] Implement structured output quality scoring

- [ ] **Task 6: Error handling and fallback strategies** (AC: 6)
  - [ ] Handle LLM API failures with graceful degradation
  - [ ] Implement timeout handling for LLM processing
  - [ ] Create fallback to rule-based extraction when LLM fails
  - [ ] Add retry logic for transient LLM API errors
  - [ ] Implement partial processing when some slots cannot be filled

- [ ] **Task 7: Performance optimization** (AC: 7)
  - [ ] Profile LLM processing performance with various clinical text lengths
  - [ ] Implement prompt optimization for faster LLM responses
  - [ ] Add caching for repeated clinical patterns
  - [ ] Optimize parallel processing of NLP pipeline stages
  - [ ] Monitor and maintain <2s total response time requirement

- [ ] **Task 8: Testing and validation** (All ACs)
  - [ ] Create comprehensive structured output tests with medical scenarios
  - [ ] Test schema validation with valid and invalid medical data
  - [ ] Validate medical reasoning accuracy with clinical examples
  - [ ] Integration testing with Story 2.1 and 2.2 components
  - [ ] Performance testing to ensure <2s response time compliance

## Dev Notes

### Integration with Epic 2 Foundation
**NLP Pipeline Enhancement Architecture**:
- **Story 2.1**: spaCy/medspaCy entity extraction → base medical entities
- **Story 2.2**: ChromaDB RAG enhancement → standardized medical terminology
- **Story 2.3**: LLM structured processing → comprehensive medical data structure
- **Combined Output**: Rich, validated, structured medical information ready for FHIR assembly

### LLM Technology Stack [Source: prd/5-functional-requirements.md#5.2, prd/17-model-recommendation-cost.md]
**Structured LLM Options**:
- **PydanticAI** - Schema-first LLM integration with Pydantic validation
- **Instructor + OpenAI** - Alternative structured output framework
- **OpenAI GPT-4o mini** - Recommended model for cost/performance balance
- **OpenAI Structured Outputs** - Native structured output support

### Medical Schema Design Philosophy
**Comprehensive Medical Data Structure**:
```python
# Example Schema Structure
class MedicationOrder(BaseModel):
    medication: str  # From Story 2.1 + 2.2 (entity + RxNorm code)
    dosage: DosageSchema
    frequency: FrequencySchema
    duration: Optional[str]
    indication: Optional[str]
    clinical_context: Optional[ClinicalContext]
    
class DosageSchema(BaseModel):
    amount: float
    unit: str  # mg, ml, tablets, etc.
    route: Optional[str]  # oral, IV, topical, etc.
    
class ClinicalContext(BaseModel):
    symptoms: List[str]
    medical_history: Optional[str]
    urgency: Optional[str]
```

### Performance and Cost Optimization [Source: CLAUDE.md#Performance-Requirements]
**LLM Processing Constraints**:
- **<2s total response time** - Including entity extraction + RAG + LLM processing
- **Cost efficiency** - Use GPT-4o mini for optimal cost/performance ratio
- **Prompt optimization** - Minimize token usage while maintaining accuracy
- **Caching strategy** - Cache structured outputs for similar clinical patterns

### Security and HIPAA Considerations
**PHI Handling in LLM Processing**:
- **Anonymize clinical text** - Remove or mask patient identifiers before LLM processing
- **No PHI in prompts** - Use anonymized clinical scenarios for LLM processing
- **Secure API communication** - Encrypt all LLM API communications
- **Audit LLM usage** - Log LLM processing without exposing clinical content

### Enhanced NLP Pipeline Architecture
```
Clinical Text Input
    ↓
Story 2.1: spaCy/medspaCy Entity Extraction
    ↓
Story 2.2: ChromaDB RAG Medical Terminology Enhancement  
    ↓
Story 2.3: LLM Structured Processing & Slot Filling
    ├── Schema-Constrained Output Generation
    ├── Medical Validation & Reasoning
    ├── Clinical Context Extraction
    └── Structured Data Quality Scoring
    ↓
Comprehensive Structured Medical Data
    ↓
Epic 3: FHIR Bundle Assembly
```

### Project Structure Enhancement
Building on Stories 2.1 and 2.2:
```
├── services/
│   ├── nlp/
│   │   ├── pipeline.py              # Enhanced with LLM integration
│   │   ├── entity_extractor.py      # Story 2.1
│   │   ├── rag_service.py           # Story 2.2  
│   │   ├── llm_processor.py         # NEW: LLM structured processing
│   │   ├── schema_validator.py      # NEW: Medical schema validation
│   │   └── data_fusion.py           # NEW: Combine all NLP results
├── models/
│   ├── medical_schemas.py           # NEW: Pydantic medical data schemas
│   ├── llm_models.py                # NEW: LLM request/response models
│   └── structured_output.py         # NEW: Combined structured output models
├── utils/
│   ├── llm_client.py                # NEW: OpenAI/PydanticAI client
│   ├── prompt_templates.py          # NEW: Medical prompt templates
│   ├── medical_validators.py        # Enhanced from Story 2.2
│   └── anonymization.py            # NEW: PHI anonymization utilities
├── tests/
│   ├── llm/
│   │   ├── test_structured_output.py # LLM output validation tests
│   │   ├── test_medical_schemas.py   # Schema validation tests
│   │   ├── test_integration.py       # Full pipeline integration tests
│   │   └── test_performance.py       # Performance and timing tests
```

### Medical Reasoning Examples
**Complex Clinical Scenario Processing**:
```
Input: "Start John on metformin 500mg twice daily with meals for his diabetes, 
       increase to 850mg if blood glucose remains elevated after 2 weeks"

LLM Structured Output:
{
  "medication_order": {
    "medication": "metformin",
    "rxnorm_code": "6809",  // From Story 2.2 RAG
    "initial_dosage": {"amount": 500, "unit": "mg"},
    "frequency": {"times_per_day": 2, "timing": "with_meals"},
    "indication": "diabetes mellitus",
    "titration_plan": {
      "condition": "elevated_blood_glucose", 
      "timeframe": "2_weeks",
      "adjustment": {"amount": 850, "unit": "mg"}
    }
  },
  "clinical_context": {
    "condition": "diabetes mellitus",
    "monitoring_required": "blood_glucose",
    "follow_up_needed": true
  }
}
```

### Testing Strategy
**LLM-Specific Testing Requirements**:
- **Schema Validation**: Test Pydantic schema enforcement with medical data
- **Medical Reasoning**: Validate LLM understanding of clinical scenarios  
- **Integration Testing**: Verify seamless integration with Stories 2.1 and 2.2
- **Performance Testing**: Ensure LLM processing maintains <2s total requirement
- **Error Recovery**: Test LLM failure scenarios and fallback mechanisms

**Clinical Reasoning Test Cases**:
```
"Complex dosing with titration schedules"
"Multi-medication orders with interactions"
"Laboratory orders with specific timing requirements"
"Procedure orders with preparation instructions"
"Emergency vs routine clinical scenarios"
```

### Future Epic Integration  
**Epic 3 - FHIR Bundle Assembly Preparation**:
- Structured medical data ready for direct FHIR resource mapping
- Medical validation results available for FHIR compliance checking
- Clinical reasoning context available for complex FHIR resource relationships

**Epic 4 - Reverse Validation Integration**:
- Structured clinical context available for intelligent bundle summarization
- Medical reasoning available for explaining clinical decision logic

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-09 | 1.0 | Initial story creation for Epic 2 LLM integration | Scrum Master (Bob) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*Results from QA Agent review will be populated here after implementation*