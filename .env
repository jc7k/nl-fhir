# NL-FHIR Environment Configuration
# Copy this file to .env and update values for your environment

# Application Settings
ENVIRONMENT=development
APP_NAME=nl-fhir-converter
APP_VERSION=1.0.0
LOG_LEVEL=INFO

# Security Settings
SECRET_KEY=your-secret-key-here-change-in-production
ALLOWED_HOSTS=["localhost","127.0.0.1","*.railway.app"]
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]
TRUSTED_HOSTS=["localhost","127.0.0.1","*.railway.app"]

# Performance Settings
MAX_REQUEST_SIZE_MB=1
REQUEST_TIMEOUT_SECONDS=30
RATE_LIMIT_REQUESTS_PER_MINUTE=100
WORKERS=4

# Monitoring Settings
ENABLE_METRICS=true
ENABLE_HEALTH_CHECK=true
METRICS_PORT=9090

# Future Epic 2 - NLP Pipeline
# SPACY_MODEL=en_core_web_sm
# MEDSPACY_ENABLED=true
# NLP_CACHE_ENABLED=true
# NLP_CACHE_TTL_SECONDS=3600

# Future Epic 3 - FHIR Integration
# HAPI_FHIR_URL=http://localhost:8080/fhir
# HAPI_FHIR_TIMEOUT_SECONDS=10
# FHIR_VALIDATION_ENABLED=true
# FHIR_VERSION=R4

# LLM Integration - OpenAI API for Enhanced Structured Output
OPENAI_API_KEY=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
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.0
OPENAI_MAX_TOKENS=2000
OPENAI_TIMEOUT_SECONDS=30

# LLM Processing Settings
LLM_ENABLED=true
LLM_FALLBACK_ENABLED=true
INSTRUCTOR_ENABLED=true

# Epic 4 - Reverse Validation
SUMMARIZATION_ENABLED=true
SAFETY_VALIDATION_ENABLED=true

# Future Epic 5 - Deployment
# RAILWAY_ENVIRONMENT=production
# WORKERS=4
# DATABASE_URL=postgresql://user:pass@localhost/nlfi-hr
# REDIS_URL=redis://localhost:6379
# SENTRY_DSN=your-sentry-dsn-here
